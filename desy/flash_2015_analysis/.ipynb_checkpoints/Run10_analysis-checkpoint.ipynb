{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# magic incantation to make the notebook wider\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:90% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#magic incantation to make all text in LaTeX font:\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'serif','serif':['Computer Modern Roman']})\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "import os, sys\n",
    "%matplotlib inline\n",
    "\n",
    "import new_functions as fn\n",
    "fn = reload(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RUN = 10\n",
    "# RUN = 21\n",
    "RUN = 14\n",
    "\n",
    "if RUN == 10:\n",
    "    beam_mon_file = '/Users/mfisherlevine/Desktop/desy/RUN10.txt'\n",
    "    timepix_data_dir = '/Users/mfisherlevine/Desktop/desy/Data/Run10/'\n",
    "    MCP_file = ''\n",
    "elif RUN == 21:\n",
    "    beam_mon_file = '/Users/mfisherlevine/Desktop/desy/RUN21.txt'\n",
    "    timepix_data_dir = '/Users/mfisherlevine/Desktop/desy/Data/Run21/'\n",
    "    MCP_file = ''\n",
    "elif RUN == 14:\n",
    "    beam_mon_file = '/Users/mfisherlevine/Desktop/desy/RUN21.txt'\n",
    "    timepix_data_dir = '/Users/mfisherlevine/Desktop/desy/Data/Run14/'\n",
    "    MCP_file = ''\n",
    "else:\n",
    "    print 'ERROR: Bad run number'\n",
    "tp_datafiles = [timepix_data_dir + _ for _ in os.listdir(timepix_data_dir)]\n",
    "print 'Found %s datafiles for run %s'%(len(tp_datafiles), RUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pids, bids, tunnels = pl.loadtxt(beam_mon_file, usecols = (0,1,2), skiprows=1, unpack=True)\n",
    "\n",
    "# dropped bunches have pid of zero, so clean these up\n",
    "n_dropped = 0\n",
    "for i, pid in enumerate(pids): \n",
    "    if pid == 0.0:\n",
    "        pids[i] = pids[i-1] + 1\n",
    "        n_dropped +=1\n",
    "print 'Fixed %s dropped shots'%n_dropped\n",
    "#pids are now contiguous\n",
    "\n",
    "beam_data = {}\n",
    "for pid, bid in zip(pids, bids):\n",
    "    beam_data[pid] = bid\n",
    "del pids, bids, tunnels # remove others to save from accidentally using them incorrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tp_data = {}\n",
    "n_files_loaded = 0\n",
    "for filename in tp_datafiles:\n",
    "    bunchID = fn.GetBunchIDFromFile(filename)\n",
    "    n_codes = fn.Get_n_timecodesFromFile(filename)\n",
    "    if not bunchID in tp_data.keys():\n",
    "        tp_data[bunchID] = {}\n",
    "        tp_data[bunchID]['n_codes'] = n_codes\n",
    "        tp_data[bunchID]['filename'] = filename\n",
    "    else:\n",
    "        print 'Would have overwritten bunchID %s'%bunchID\n",
    "    n_files_loaded += 1\n",
    "\n",
    "print '*****\\nLoaded %s files' %n_files_loaded\n",
    "print 'Found %s unique bunchIDs'%len(tp_data)\n",
    "print '(Difference = %s)'%(n_files_loaded-len(tp_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_skipped = 0\n",
    "offsets = [0]\n",
    "for offset in offsets:\n",
    "    xs, ys = [], []\n",
    "    for bunchID in tp_data.keys():\n",
    "        try:\n",
    "            xs.append(beam_data[bunchID + offset])\n",
    "            ys.append(tp_data[bunchID]['n_codes'])\n",
    "        except:\n",
    "            pass\n",
    "    print 'Offset %s:'%offset\n",
    "    pl.plot(xs, ys, 'x', markersize=2)\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.ndimage as ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import SmartCentroider\n",
    "SmartCentroider = reload(SmartCentroider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = SmartCentroider.SmartCentroider(tp_datafiles)\n",
    "sc.skiplines = 1\n",
    "sc.ToF_noise_threshold = 200\n",
    "sc.n_tof_files = 500\n",
    "sc.TMAX = 9500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc.MakeSampleTOF()\n",
    "sc.CalculateBands()\n",
    "\n",
    "print 'Smoothed, noise suppressed and truncated ToF spectrum for sample files'\n",
    "sc.ShowTOF(sc.sample_TOF_smoothed)\n",
    "sc.ShowBands()\n",
    "sc.PrintBandsForEditing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sc.bands = [(8260-8,8260+8)]\n",
    "sc.bands = [(0,11810)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sc.SaveToPickle('/Users/mfisherlevine/Desktop/desy/run21_no_bands.pickle')\n",
    "sc = SmartCentroider.SmartCentroider('/Users/mfisherlevine/Desktop/desy/run21_no_bands.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VMI_bands = [(8200, 8209),\n",
    "         (8209, 8223),\n",
    "         (8223, 8243),\n",
    "         (8243, 8267),\n",
    "         (8267, 8289),\n",
    "         (8289, 8323),\n",
    "         (8323, 8356),\n",
    "         (8356, 8382),\n",
    "         (8382, 8403),\n",
    "         (8403, 8445),\n",
    "         (8445, 8488),\n",
    "         (8488, 8507)]\n",
    "\n",
    "sc.npix_per_cluster_cut = (0,1e9)\n",
    "\n",
    "sc.MakeVMIsFromBands(custom_bands=VMI_bands, use_gaussians=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SmartCentroider = reload(SmartCentroider)\n",
    "new_sc = sc.DataFrom(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testfile = '/Users/mfisherlevine/Desktop/test.pickle'\n",
    "new_sc.SaveToPickle(testfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SmartCentroider = reload(SmartCentroider)\n",
    "loaded_sc = SmartCentroider.SmartCentroider(testfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "new_sc.ShowAllVMIs(vmax='auto', white_background=True, white_background_threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VMI_bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_sc.bands = [(8260-8,8260+8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_sc.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_sc.MakeVMIsFromBands(use_gaussians=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_sc.ShowAllVMIs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.BuildMainTOF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import new_functions as fn\n",
    "fn = reload(fn)\n",
    "import pylab as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "print sc.main_TOF[0,0], sc.main_TOF[-1,0]\n",
    "plt.step(sc.main_TOF[:,0], sc.main_TOF[:,1])\n",
    "collapsed_bands = fn.CollapseBands(sc.bands)\n",
    "\n",
    "plt.plot(collapsed_bands, [500 for _ in collapsed_bands], 'ro')\n",
    "plt.xlim(pl.xlim()[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc2.bands = [(8135, 8170),\n",
    "         (8170, 8210),\n",
    "         (8210, 8224),\n",
    "         (8224, 8244),\n",
    "         (8244, 8267),\n",
    "         (8267, 8289),\n",
    "         (8289, 8317),\n",
    "         (8317, 8338),\n",
    "         (8338, 8351),\n",
    "         (8351, 8362),\n",
    "         (8362, 8382),\n",
    "         (8382, 8403),\n",
    "         (8403, 8425),\n",
    "         (8425, 8460),\n",
    "         (8460, 8488),\n",
    "         (8488, 8550)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = sc.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc2 = SmartCentroider.SmartCentroider(tp_datafiles)\n",
    "sc2.skiplines = 1\n",
    "sc2.ToF_noise_threshold = 200\n",
    "sc2.n_tof_files = 500\n",
    "sc2.TMAX = 9500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc2.bands = [(0,11810)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data2 = sc2.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc2.BuildMainTOF()\n",
    "sc2.bands = [(8000, 8325),\n",
    "             (8325, 8450),\n",
    "             (8450, 8488),\n",
    "             (8488, 8550)]\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.step(sc2.main_TOF[:,0], sc2.main_TOF[:,1])\n",
    "collapsed_bands = fn.CollapseBands(sc2.bands)\n",
    "plt.plot(collapsed_bands, [500 for _ in collapsed_bands], 'ro')\n",
    "plt.xlim((8507,8201))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc3 = SmartCentroider.SmartCentroider(tp_datafiles)\n",
    "sc3.skiplines = 1\n",
    "sc3.ToF_noise_threshold = 200\n",
    "sc3.n_tof_files = 500\n",
    "sc3.TMAX = 9500\n",
    "sc3.bands = [(8000, 8325),\n",
    "             (8325, 8450),\n",
    "             (8450, 8488),\n",
    "             (8488, 8550)]\n",
    "\n",
    "data3 = sc3.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc3.BuildMainTOF()\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.step(sc.main_TOF[:,0], sc.main_TOF[:,1] ,'g')\n",
    "plt.step(sc2.main_TOF[:,0], sc2.main_TOF[:,1] ,'b')\n",
    "plt.step(sc3.main_TOF[:,0], sc3.main_TOF[:,1] ,'r')\n",
    "\n",
    "collapsed_bands = fn.CollapseBands(sc3.bands)\n",
    "# plt.plot(collapsed_bands, [500 for _ in collapsed_bands], 'ro')\n",
    "plt.xlim((8507,8201))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc4 = SmartCentroider.SmartCentroider(tp_datafiles)\n",
    "sc4.skiplines = 1\n",
    "sc4.ToF_noise_threshold = 200\n",
    "sc4.n_tof_files = 500\n",
    "sc4.TMAX = 9500\n",
    "sc4.bands = [(8000, 8325),\n",
    "             (8325, 8450),\n",
    "             (8450, 8489),\n",
    "             (8489, 8550)]\n",
    "\n",
    "data3 = sc4.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "sc4.BuildMainTOF()\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.step(sc4.main_TOF[:,0], sc4.main_TOF[:,1] ,'g')\n",
    "plt.step(sc2.main_TOF[:,0], sc2.main_TOF[:,1] ,'b')\n",
    "plt.step(sc3.main_TOF[:,0], sc3.main_TOF[:,1] ,'r')\n",
    "\n",
    "collapsed_bands = fn.CollapseBands(sc3.bands)\n",
    "# plt.plot(collapsed_bands, [500 for _ in collapsed_bands], 'ro')\n",
    "plt.xlim((8507,8201))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxval = int(np.max(img)) #get largest timecode\n",
    "minval = int(np.min(img[img>0])) #get smallest non-zero timecode\n",
    "# a,b,c =pl.hist(img[img>0],bins = (maxval-minval)+1)\n",
    "ys = ndimage.histogram(img[img>0],minval,maxval,bins = (maxval-minval)+1) #much faster than pl.hist\n",
    "xs = np.linspace(minval,maxval,(maxval-minval+1)) #make x points for ToF plot\n",
    "f = pl.figure(figsize=[12,4]) #Make the figure an appropriate shape\n",
    "pl.plot(xs,ys,'b') #plot the original ToF\n",
    "pl.xlim(minval,maxval) #set limits as python is weird sometimes\n",
    "new_ys = scipy.signal.savgol_filter(ys,5,3) # smooth the ToF as it's only a single shot\n",
    "pl.plot(xs,new_ys,'r')#plot the new, smoothed ToF\n",
    "max_indexes = scipy.signal.argrelmax(new_ys, axis=0, order=20) #find local maxima, range of 5 each side\n",
    "peaks = [xs[_] for _ in max_indexes[0]] # Get peak location from indices\n",
    "\n",
    "bands = [] # generate banks from peaks - need to take the midpoints though!\n",
    "bands.append((minval,(peaks[0]+peaks[1])//2)) #first point to midpoint of first peaks\n",
    "for i in xrange(1,len(peaks)-1):\n",
    "    bands.append((bands[-1][1],(peaks[i]+peaks[i+1])//2)) # loop through\n",
    "bands.append((bands[-1][0],maxval))# add last midpoint to last value\n",
    "\n",
    "\n",
    "pl.plot(peaks,[-10 for _ in max_indexes[0]],'bo') # plot peaks in blue\n",
    "pl.plot([_[0] for _ in bands],[10 for _ in bands],'ro') # plot left band boundaries in red\n",
    "pl.plot([_[1] for _ in bands],[10 for _ in bands],'ro') # plot right band boundaries in red too\n",
    "pl.show()\n",
    "   \n",
    "##########\n",
    "f = pl.figure(figsize=[12,4]) #Make the figure an appropriate shape\n",
    "a,b,c = pl.hist(t_centroids,max(t_centroids)-min(t_centroids)+1)\n",
    "pl.xlim(minval,maxval) #set limits as python is weird sometimes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "struct_el=[[0,1,0],[1,1,1],[0,1,0]] # for vertical/horizontal connections only\n",
    "# struct_el=[[1,1,1],[1,1,1],[1,1,1]] # for including diagonal connections as well\n",
    "\n",
    "from scipy.ndimage.measurements import center_of_mass, maximum_position\n",
    "\n",
    "segmentation,segments=scipy.ndimage.label(img,struct_el) # find clusters\n",
    "print 'Found %s clusters without using band information'%segments\n",
    "\n",
    "print 'Using %s bands...'%len(bands)\n",
    "seg_sum = 0\n",
    "t_centroids = []\n",
    "for i,(tmin, tmax) in enumerate(bands):\n",
    "#     if i!=6: continue\n",
    "    band_img = img.copy() #make a copy\n",
    "    band_img[band_img > tmax] = 0 #threshold new image\n",
    "    band_img[band_img <= tmin] = 0\n",
    "\n",
    "#     f = pl.figure(figsize=[8,8]) \n",
    "#     pl.imshow(band_img)\n",
    "    \n",
    "    segmentation,segments = scipy.ndimage.label(band_img,struct_el) # find clusters\n",
    "    CoMs = center_of_mass(band_img, segmentation, [_ for _ in xrange(1,segments+1)])\n",
    "#     CoMs = maximum_position(band_img, segmentation, [_ for _ in xrange(1,segments+1)])\n",
    "#     print CoMs\n",
    "#     index = (np.asarray([_[0] for _ in CoMs]),np.asarray([[_[1] for _ in CoMs]]))\n",
    "#     codes = img[CoMs]\n",
    "    for com in CoMs:\n",
    "        t_centroids.append(img[com])\n",
    "#     break\n",
    "#     for clust_num in xrange(1,segments): # cluster 0 = background\n",
    "#         clust_pix = np.where(segmentation==clust_num)\n",
    "#         t_centroids.append(np.max(img[clust_pix]))\n",
    "\n",
    "#     print 'Found %s segs in band %s (%s - %s)'%(segments,i, tmin, tmax)\n",
    "    seg_sum += segments\n",
    "#     break\n",
    "\n",
    "print 'Found %s clusters when using bands'%seg_sum\n",
    "print t_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = pl.figure(figsize=[8,8]) \n",
    "\n",
    "pl.imshow(segmentation)\n",
    "print type(segmentation[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# struct_el=[[0,1,0],[1,1,1],[0,1,0]] # for vertical/horizontal connections only\n",
    "# # struct_el=[[1,1,1],[1,1,1],[1,1,1]] # for including diagonal connections as well\n",
    "\n",
    "# # import scipy.ndimage.measurements.center_of_mass as center_of_mass\n",
    "\n",
    "# segmentation,segments=scipy.ndimage.label(img,struct_el) # find clusters\n",
    "# print 'Found %s clusters without using band information'%segments\n",
    "\n",
    "# print 'Using %s bands...'%len(bands)\n",
    "# seg_sum = 0\n",
    "# t_centroids = []\n",
    "# now = time.time()\n",
    "# for filename in tp_datafiles[0:100]:\n",
    "#     for i,(tmin, tmax) in enumerate(bands):\n",
    "#         band_img = img.copy() #make a copy\n",
    "#         band_img[band_img > tmax] = 0 #threshold new image\n",
    "#         band_img[band_img <= tmin] = 0\n",
    "\n",
    "#         segmentation,segments=scipy.ndimage.label(band_img,struct_el) # find clusters\n",
    "#         for clust_num in xrange(1,segments): # cluster 0 = background\n",
    "#             clust_pix = np.where(segmentation==clust_num)\n",
    "#             t_centroids.append(np.max(img[clust_pix]))\n",
    "        \n",
    "#     #     print 'Found %s segs in band %s (%s - %s)'%(segments,i, tmin, tmax)\n",
    "#         seg_sum += segments\n",
    "# print 'Time = %s secs'%(time.time()-now)\n",
    "# print 'Found %s clusters when using bands'%seg_sum\n",
    "# # print t_centroids\n",
    "\n",
    "###########\n",
    "\n",
    "struct_el=[[0,1,0],[1,1,1],[0,1,0]] # for vertical/horizontal connections only\n",
    "# struct_el=[[1,1,1],[1,1,1],[1,1,1]] # for including diagonal connections as well\n",
    "\n",
    "# import scipy.ndimage.measurements.center_of_mass as center_of_mass\n",
    "\n",
    "segmentation,segments=scipy.ndimage.label(img,struct_el) # find clusters\n",
    "print 'Found %s clusters without using band information'%segments\n",
    "\n",
    "print 'Using %s bands...'%len(bands)\n",
    "seg_sum = 0\n",
    "t_centroids = []\n",
    "now = time.time()\n",
    "for filenum, filename in enumerate(tp_datafiles):\n",
    "    if filenum%1000==0: print 'Processed %s files'%filenum\n",
    "    img = fn.TimepixFileToImage(filename)\n",
    "    for i,(tmin, tmax) in enumerate(bands):\n",
    "        band_img = img.copy() #make a copy\n",
    "        band_img[band_img > tmax] = 0 #threshold new image\n",
    "        band_img[band_img <= tmin] = 0\n",
    "\n",
    "        segmentation,segments = scipy.ndimage.label(band_img,struct_el) # find clusters\n",
    "#         CoMs = center_of_mass(band_img, segmentation, [_ for _ in xrange(1,segments+1)])\n",
    "        CoMs = maximum_position(band_img, segmentation, [_ for _ in xrange(1,segments+1)])\n",
    "        for com in CoMs:\n",
    "            t_centroids.append(img[com])\n",
    "        seg_sum += segments\n",
    "\n",
    "print 'Time = %s secs'%(time.time()-now)\n",
    "print 'Found %s clusters when using bands'%seg_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = pl.figure(figsize=[16,4])\n",
    "ax = pl.subplot(111)\n",
    "print len(t_centroids)\n",
    "print 'As a histogram:'\n",
    "ys, binEdges, dummy = pl.hist(all_ts, bins=bins, range=range, histtype = 'step')\n",
    "bincenters = 0.5*(binEdges[1:]+binEdges[:-1])\n",
    "turn_cent, stat_cent, troughs_cent, peaks_cent = fn.GetTurningPoints(ys, bincenters, noise=50)\n",
    "lims = pl.ylim()\n",
    "pl.ylim([lims[0], y_rescale*max(ys)])\n",
    "ax.set_xticks(troughs_cent, minor=False)\n",
    "ax.xaxis.grid(True, which='major')\n",
    "pl.show()\n",
    "\n",
    "fig = pl.figure(figsize=[16,4])\n",
    "pl.hist([((11810-_-TZERO)*20) for _ in t_centroids], bins, range=range, histtype = 'step')\n",
    "\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters = segmentation.copy() # make a copy to preserve original image\n",
    "for i in xrange(1,segments+1):# loop over clusters\n",
    "    clusters[clusters==i]=np.random.randint(0,segments+1) #colour each cluster a random colour\n",
    "clusters[clusters==0]=np.nan #for a white background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = pl.figure(figsize=[8,8])\n",
    "pl.imshow(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fn = reload(fn)\n",
    "TCUT = 8000\n",
    "print tp_datafiles[0]\n",
    "\n",
    "fn.ShowClusteredImage(tp_datafiles[1],TCUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'hello'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = reload(fn)\n",
    "import cPickle as pickle\n",
    "\n",
    "# NB These are different units!\n",
    "TCUT = 257 #Raw timecode cut for centroiding\n",
    "TZERO = 3300 #Time, in ns, after inversion and conversion, to set as t0\n",
    "\n",
    "run_id = '%s_tcut%s_tzero%s'%(RUN, TCUT, TZERO)\n",
    "pickle_filename = '/Users/mfisherlevine/Desktop/desy/pickles/tp_data_run'+run_id+'.pickle'\n",
    "\n",
    "now = time.time()\n",
    "# if False:\n",
    "if not os.path.exists(pickle_filename):\n",
    "    for i, bunchID in enumerate(tp_data.keys()):\n",
    "    #     if 'ts' in tp_data[bunchID].keys(): continue #already loaded\n",
    "        if i%100==0:print 'Centroided %s frames'%i; sys.stdout.flush()\n",
    "\n",
    "        filename = tp_data[bunchID]['filename']\n",
    "        dummy, xs, ys, ts, npixs = fn.GetCentroidsXYTFromFile(filename, TCUT)#, gating=[8400,8])\n",
    "        tp_data[bunchID]['xs'] = xs\n",
    "        tp_data[bunchID]['ys'] = ys\n",
    "        tp_data[bunchID]['ts'] = [(_-TZERO)*20 for _ in ts]#already inverted, just translate to ns\n",
    "        tp_data[bunchID]['npixs'] = npixs\n",
    "        tp_data[bunchID]['n_ions'] = len(xs)\n",
    "\n",
    "    pickle_file = open(pickle_filename, 'wb')\n",
    "    pickle.dump(tp_data, pickle_file)\n",
    "    pickle_file.close()\n",
    "    print 'Took %s secs'%(time.time() - now)\n",
    "\n",
    "else:\n",
    "    print 'Unpickling...'; sys.stdout.flush()\n",
    "#     pickle_filename = '/Users/mfisherlevine/Desktop/desy/pickles/tp_data_run'+str(RUN)+'.pickle'\n",
    "    pickle_file = open(pickle_filename, 'rb')\n",
    "    tp_data = pickle.load(pickle_file)\n",
    "    pickle_file.close()\n",
    "    print 'Loaded %s pickled entries'%len(tp_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Put all the centroided timecodes in a single list for convenience\n",
    "all_ts = []\n",
    "n_loaded = 0\n",
    "for bunchID in tp_data.keys():\n",
    "    if 'ts' in tp_data[bunchID].keys():\n",
    "        all_ts.extend(tp_data[bunchID]['ts'])\n",
    "        n_loaded += 1\n",
    "print 'Collated centroided timecodes from %s shots'%n_loaded\n",
    "print '%s times in total'%len(all_ts)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Make the same plot as before, but plotting the number of ions, rather than the number of timecodes. After that, we'll look at the correlation for single ion species (just because it's easy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_skipped = 0\n",
    "offsets = [0]\n",
    "for offset in offsets:\n",
    "    xs, ys = [], []\n",
    "    for bunchID in tp_data.keys():\n",
    "        try:\n",
    "            ys.append(tp_data[bunchID]['n_ions']) #NB has to be this one first due to dropped frames\n",
    "            xs.append(beam_data[bunchID + offset])\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    print 'Offset %s:'%offset\n",
    "    pl.plot(xs, ys, 'x', markersize=2)\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's look at the TOF spectrum, including the raw spectrum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the raw timecodes, converting the same way as the others\n",
    "raw_timecodes = []\n",
    "for i, filename in enumerate(tp_datafiles):\n",
    "    if i==1000: print 'Loaded %s files'%i; sys.stdout.flush()\n",
    "    raw_timecodes.extend(((11810-_)-TZERO)*20 for _ in fn.GetTimecodes_SingleFile(filename, skiplines=1))\n",
    "print 'Loaded %s raw timecodes'%len(raw_timecodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# range = [0,9000]\n",
    "range = [0,6000]\n",
    "# range = [4000,5000]\n",
    "\n",
    "############\n",
    "# for the raw spectrum:\n",
    "\n",
    "y_rescale = 1 # big peak is too big, so clip y-axis by rescaling to this fraction of max\n",
    "bins = min(int((max(raw_timecodes)-min(raw_timecodes)+1)),(range[1]-range[0]+1))//20\n",
    "\n",
    "fig = pl.figure(figsize=[16,4])\n",
    "ax = pl.subplot(111)\n",
    "\n",
    "# as a hist\n",
    "print 'Raw timecodes a histogram:'\n",
    "ys, binEdges, dummy = pl.hist(raw_timecodes, bins=bins, range=range, histtype = 'step')\n",
    "bincenters = 0.5*(binEdges[1:]+binEdges[:-1])\n",
    "lims = pl.ylim()\n",
    "pl.ylim([lims[0], y_rescale*max(ys)])\n",
    "# ax.set_xticks(ticks, minor=False)\n",
    "turn_raw, stat_raw, troughs_raw, peaks_raw = fn.GetTurningPoints(ys, bincenters, noise=500)\n",
    "ax.set_xticks(troughs_raw, minor=False)\n",
    "ax.xaxis.grid(True, which='major')\n",
    "pl.show()\n",
    "\n",
    "\n",
    "############\n",
    "# for the centroided spectrum:\n",
    "\n",
    "y_rescale = 0.3 # big peak is too big, so clip y-axis by rescaling to this fraction of max\n",
    "bins = min(int((max(all_ts)-min(all_ts)+1)),(range[1]-range[0]+1))//20\n",
    "\n",
    "fig = pl.figure(figsize=[16,4])\n",
    "ax = pl.subplot(111)\n",
    "\n",
    "# as a hist\n",
    "print 'As a histogram:'\n",
    "ys, binEdges, dummy = pl.hist(all_ts, bins=bins, range=range, histtype = 'step')\n",
    "bincenters = 0.5*(binEdges[1:]+binEdges[:-1])\n",
    "turn_cent, stat_cent, troughs_cent, peaks_cent = fn.GetTurningPoints(ys, bincenters, noise=50)\n",
    "lims = pl.ylim()\n",
    "pl.ylim([lims[0], y_rescale*max(ys)])\n",
    "ax.set_xticks(troughs_cent, minor=False)\n",
    "ax.xaxis.grid(True, which='major')\n",
    "pl.show()\n",
    "\n",
    "# as a line graph\n",
    "print 'As a line graph:'\n",
    "fig = pl.figure(figsize=[16,4])\n",
    "ax = pl.subplot(111)\n",
    "bincenters = 0.5*(binEdges[1:]+binEdges[:-1])\n",
    "a = pl.plot(bincenters, ys,'r-')\n",
    "lims = pl.ylim()\n",
    "pl.ylim([lims[0], y_rescale*max(ys)])\n",
    "minor_spacing = 200\n",
    "xlims = pl.xlim()\n",
    "# ticks = [_ * minor_spacing for _ in xrange(int(xlims[1]-xlims[0])//minor_spacing)]\n",
    "ax.set_xticks(troughs_cent, minor=False)\n",
    "ax.xaxis.grid(True, which='major')\n",
    "pl.show()\n",
    "# ax.set_autoscale_on(False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Create a list of tuples with the bands in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bands = []\n",
    "for i in xrange(len(troughs_cent)-1):\n",
    "    bands.append((troughs_cent[i],troughs_cent[i+1]))\n",
    "print bands"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "These are a good starting point, but let's re-define them by hand so we can tweak their values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if RUN==10:\n",
    "    bands = [( 30.0, 140.0), \n",
    "             (140.0, 500.0),\n",
    "             (500.0, 750.0),\n",
    "             (750.0, 1490.0),\n",
    "             (1490.0, 1710.0),\n",
    "             (1710.0, 1870.0),\n",
    "             (1870.0, 1950.0),\n",
    "             (1950.0, 2070.0),\n",
    "             (2070.0, 2210.0),\n",
    "             (2210.0, 2650.0),\n",
    "             (2650.0, 2750.0),\n",
    "             (2750.0, 2810.0),\n",
    "             (2810.0, 2950.0),\n",
    "             (2950.0, 3210.0),\n",
    "             (3210.0, 3490.0),\n",
    "             (3490.0, 3930.0),\n",
    "             (3930.0, 4070.0),\n",
    "             (4070.0, 4370.0),\n",
    "             (4370.0, 4510.0),\n",
    "             (4510.0, 4790.0),\n",
    "             (4790.0, 4830.0),\n",
    "             (4830.0, 4910.0),\n",
    "             (4910.0, 5030.0),\n",
    "             (5030.0, 5530.0),\n",
    "             (5530.0, 5710.0),\n",
    "             (5710.0, 5970.0)]\n",
    "\n",
    "# grab the first of each of these tuples, and append the last to get back the edges\n",
    "band_edges = [_[0] for _ in bands]; band_edges.append(bands[-1][1])\n",
    "print band_edges"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's replot the centroided historgram with our tweaked bands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# range = [0,9000]\n",
    "range = [0,6000]\n",
    "\n",
    "############\n",
    "# for the centroided spectrum:\n",
    "\n",
    "y_rescale = 0.3 # big peak is too big, so clip y-axis by rescaling to this fraction of max\n",
    "bins = min(int((max(all_ts)-min(all_ts)+1)),(range[1]-range[0]+1))//20\n",
    "\n",
    "fig = pl.figure(figsize=[16,4])\n",
    "ax = pl.subplot(111)\n",
    "\n",
    "# as a hist\n",
    "print 'As a histogram:'\n",
    "ys, binEdges, dummy = pl.hist(all_ts, bins=bins, range=range, histtype = 'step')\n",
    "bincenters = 0.5*(binEdges[1:]+binEdges[:-1])\n",
    "lims = pl.ylim()\n",
    "pl.ylim([lims[0], y_rescale*max(ys)])\n",
    "ax.set_xticks(band_edges, minor=False)\n",
    "ax.xaxis.grid(True, which='major')\n",
    "pl.show()\n",
    "\n",
    "#### as a line graph\n",
    "# print 'As a line graph:'\n",
    "# fig = pl.figure(figsize=[16,4])\n",
    "# ax = pl.subplot(111)\n",
    "# bincenters = 0.5*(binEdges[1:]+binEdges[:-1])\n",
    "# a = pl.plot(bincenters, ys,'r-')\n",
    "# lims = pl.ylim()\n",
    "# pl.ylim([lims[0], y_rescale*max(ys)])\n",
    "# minor_spacing = 200\n",
    "# xlims = pl.xlim()\n",
    "### ticks = [_ * minor_spacing for _ in xrange(int(xlims[1]-xlims[0])//minor_spacing)]\n",
    "# ax.set_xticks(band_edges, minor=False)\n",
    "# ax.xaxis.grid(True, which='major')\n",
    "# pl.show()\n",
    "# # ax.set_autoscale_on(False)\n",
    "print band_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Take a look at the correlation plot for each ion species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_skipped = 0\n",
    "for t_range in bands:\n",
    "    xs, ys = [], []\n",
    "    for bunchID in tp_data.keys():\n",
    "        try:\n",
    "            n_in_range = 0\n",
    "            for t in tp_data[bunchID]['ts']:\n",
    "                if t>= t_range[0] and t < t_range[1]:\n",
    "                    n_in_range += 1\n",
    "            ys.append(n_in_range) #NB has to be this one first due to dropped frames\n",
    "            xs.append(beam_data[bunchID])\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    print 'Band = %s - %s:'%(t_range[0], t_range[1])\n",
    "    pl.plot(xs, ys, 'x', markersize=2)\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Make a VMI image for each band. Whilst it looks like the loop is nested backward, I wrote it the other way around too and it's actually no faster as python's tpye checking during the band finding is so slow, and it's easier to understand and debug this way around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#probably don't need to rerun this, and it takes ages, so don't do it by accident:\n",
    "if True: \n",
    "    import time\n",
    "    now = time.time()\n",
    "    n_bunches = 999999\n",
    "\n",
    "    images = [np.zeros((256,256), dtype = np.float64) for _ in bands]\n",
    "    for i, t_range in enumerate(bands):\n",
    "        print 'Processing band %s of %s'%(i+1, len(bands))\n",
    "        for bunchID in sorted(tp_data.keys())[:min(n_bunches,tp_data.keys())]:\n",
    "            for x,y,t,npix in zip(tp_data[bunchID]['xs'],\n",
    "                                  tp_data[bunchID]['ys'],\n",
    "                                  tp_data[bunchID]['ts'],\n",
    "                                  tp_data[bunchID]['npixs']):\n",
    "                if t >= t_range[0] and t<t_range[1]:\n",
    "        #             image += makeGaussian(256,1,1.5,[x,y])\n",
    "                    images[i] += fn.makeGaussian(256,1,(npix**.5)/1.5,[x,y])\n",
    "    print 'Took %.1f secs'%(time.time()-now)\n",
    "# ### The un-debugged version that doesn't nest the loops backwards, but also doens't run faster\n",
    "# import time\n",
    "# n_bunches = 1000\n",
    "\n",
    "# outside_range = np.zeros((256,256), dtype = np.float64)\n",
    "# images = [np.zeros((256,256), dtype = np.float64) for _ in bands]\n",
    "\n",
    "# now = time.time()\n",
    "# for bunchID in sorted(tp_data.keys())[:min(n_bunches,tp_data.keys())]:\n",
    "#     for x,y,t,npix in zip(tp_data[bunchID]['xs'],\n",
    "#                           tp_data[bunchID]['ys'],\n",
    "#                           tp_data[bunchID]['ts'],\n",
    "#                           tp_data[bunchID]['npixs']):\n",
    "#         found_band = False\n",
    "#         for i, band in enumerate(bands):\n",
    "#             if t >= band[0] and t<band[1]:\n",
    "# #             image += makeGaussian(256,1,1.5,[x,y])\n",
    "#                 images[i] += fn.makeGaussian(256,1,(npix**.5)/1.5,[x,y])\n",
    "#                 found_band = True\n",
    "#             break\n",
    "#         if found_band == False:\n",
    "#             outside_range += fn.makeGaussian(256,1,(npix**.5)/1.5,[x,y])\n",
    "# print 'Took %.1f secs'%(time.time()-now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### pickle the bands and their images\n",
    "pickle_filename = '/Users/mfisherlevine/Desktop/desy/pickles/run'+run_id+'_VMIs.pickle'\n",
    "\n",
    "if False: #C areful, this will overwrite the good pickles if you accidentally run it!\n",
    "    pickle_file = open(pickle_filename, 'wb')\n",
    "    pickle.dump([bands, images], pickle_file)\n",
    "    pickle_file.close()\n",
    "\n",
    "\n",
    "#### Load the bands and their images from the pickle:\n",
    "if True:\n",
    "    print 'Unpickling...'; sys.stdout.flush()\n",
    "    pickle_file = open(pickle_filename, 'rb')\n",
    "    [bands, images] = pickle.load(pickle_file)\n",
    "    pickle_file.close()\n",
    "    print 'Loaded bands and images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print bands"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Plot all the VMI images and give them an appropraite title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fn = reload(fn)\n",
    "cmap = 'copper' ### beware using the de facto standard 'jet',\n",
    "                ### but it's also replotted below for people who can't live without it\n",
    "for i, image in enumerate(images):\n",
    "    title = 'VMI for times %s to %s (band #%s)'%(bands[i][0],bands[i][1], i)\n",
    "    fn.DisplayImage(image, cmap=cmap, title=title,vmax='auto')\n",
    "    pl.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "Again for those who are a fan of other colour maps:\n",
    "Please read this important page on choosing colour maps:\n",
    "https://jakevdp.github.io/blog/2014/10/16/how-bad-is-your-colormap/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fn = reload(fn)\n",
    "cmap = 'jet'\n",
    "for i, image in enumerate(images):\n",
    "    title = 'VMI for times %s to %s (band %s)'%(bands[i][0],bands[i][1], i)\n",
    "    fn.DisplayImage(image, cmap=cmap, title=title,vmax='auto')\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmap = 'jet'\n",
    "image = images[27].copy()\n",
    "fn.DisplayImage(image, cmap=cmap, title=title,vmax='auto')\n",
    "pl.show()\n",
    "\n",
    "import scipy.ndimage as im_process\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "\n",
    "deriv = im_process.sobel(gaussian_filter(image,3), mode='constant')\n",
    "fn.DisplayImage(deriv, cmap=cmap, title=title,vmax='auto')\n",
    "pl.show()\n",
    "\n",
    "deriv[abs(deriv)<10]=0\n",
    "fn.DisplayImage(deriv, cmap=cmap, title=title,vmax='auto')\n",
    "pl.show()\n",
    "\n",
    "deriv=abs(deriv/abs(deriv))\n",
    "fn.DisplayImage(deriv, cmap=cmap, title=title)\n",
    "pl.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import feature\n",
    "\n",
    "fn = reload(fn)\n",
    "cmap = 'jet'\n",
    "for i, image in enumerate(images):\n",
    "    image = image.copy()\n",
    "    if i!=27: continue\n",
    "#     title = 'Fit to VMI for times %s to %s (band %s)'%(bands[i][0],bands[i][1], i)\n",
    "    title = 'Band %s'%i\n",
    "\n",
    "    fn.DisplayImage(image, cmap=cmap, title=title,vmax='auto')\n",
    "#     image[image < 0.8*np.max(image)] = 0\n",
    "    image[image < np.percentile(image,97)] = 0\n",
    "\n",
    "    pl.show()\n",
    "    \n",
    "#     edges = feature.canny(image, sigma=3)\n",
    "\n",
    "    edges = feature.blob_dog(image)\n",
    "    fn.DisplayImage(edges, cmap=cmap, title=title)\n",
    "    pl.show()\n",
    "\n",
    "#     feature.\n",
    "#     x,y,r = FitCircle(deriv)\n",
    "#     DisplayImageWithFit(deriv,x,y,r,title=title)\n",
    "    \n",
    "#     pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fn = reload(fn)\n",
    "cmap = 'jet'\n",
    "for i, image in enumerate(images):\n",
    "#     if i!=3: continue\n",
    "#     title = 'Fit to VMI for times %s to %s (band %s)'%(bands[i][0],bands[i][1], i)\n",
    "    title = 'Band %s'%i\n",
    "\n",
    "    fn.DisplayImage(image, cmap=cmap, title=title,vmax='auto')\n",
    "    import scipy.ndimage as im_process\n",
    "    from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "    deriv = im_process.laplace(gaussian_filter(image,2), mode='constant')\n",
    "#     title += ' gaus, laplace'\n",
    "#     fn.DisplayImage(deriv, cmap=cmap, title=title)\n",
    "#     pl.show()\n",
    "\n",
    "    deriv[deriv < np.percentile(deriv,99.7)] = 0\n",
    "\n",
    "    title += ' 99.7th percentile cut'\n",
    "    fn.DisplayImage(deriv, cmap=cmap, title=title)\n",
    "    pl.show()\n",
    "\n",
    "    deriv=abs(deriv/abs(deriv))\n",
    "#     title += ', normed'\n",
    "#     fn.DisplayImage(deriv, cmap=cmap, title=title)\n",
    "#     pl.show()\n",
    "\n",
    "    x,y,r = FitCircle(deriv)\n",
    "    DisplayImageWithFit(deriv,x,y,r,title=title)\n",
    "    \n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y,r = FitCircle(deriv)\n",
    "x_circ, y_circ = MakeCirlePointsFromXYR(x,y,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MakeCirlePointsFromXYR(x, y, r, npts=180):\n",
    "    theta_fit = np.linspace(-np.pi, np.pi, npts)\n",
    "    xs = x + r*np.cos(theta_fit)\n",
    "    ys = y + r*np.sin(theta_fit)\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = pl.figure(figsize = [10,10])\n",
    "ax = fig.add_subplot(111)\n",
    "# ax.set_xlim([YMIN,YMAX])\n",
    "# ax.set_ylim([XMIN,XMAX])\n",
    "\n",
    "# if vmax == 'auto':\n",
    "#     element = (256*256) - 200\n",
    "#     tmp = image.flatten()\n",
    "#     tmp.sort()\n",
    "#     vmax = tmp[element]\n",
    "#     vmin = tmp[200]\n",
    "#     print 'Auto vmax = %s, real max = %s'%(vmax, np.max(image))\n",
    "\n",
    "# if vmin == 'auto':\n",
    "#     tmp = image.flatten()\n",
    "#     vmin = min(_ for _ in tmp if _ > 0)\n",
    "#     print 'Auto vmin = %s'%vmin\n",
    "\n",
    "im = ax.imshow(deriv)#, vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "pl.plot(y,x, 'x', ms=15)\n",
    "pl.plot(y_circ, x_circ, 'r-.')#, label=method_3, lw=2)\n",
    "ax.set_title(title)\n",
    "fig.colorbar(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def DisplayImageWithFit(image, x, y, r, vmin=None, vmax=None, cmap='jet', title = ''):\n",
    "    import numpy as np\n",
    "    fig = pl.figure(figsize = [10,10])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlim([0,255])\n",
    "    ax.set_ylim([0,255])\n",
    "\n",
    "    if vmax == 'auto':\n",
    "        element = (256*256) - 200\n",
    "        tmp = image.flatten()\n",
    "        tmp.sort()\n",
    "        vmax = tmp[element]\n",
    "        vmin = tmp[200]\n",
    "        print 'Auto vmax = %s, real max = %s'%(vmax, np.max(image))\n",
    "\n",
    "    if vmin == 'auto':\n",
    "        tmp = image.flatten()\n",
    "        vmin = min(_ for _ in tmp if _ > 0)\n",
    "        print 'Auto vmin = %s'%vmin\n",
    "\n",
    "    im = ax.imshow(image, vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "    \n",
    "    pl.plot(y,x, 'xb', ms=15) # x on the centre\n",
    "    x_circ, y_circ = MakeCirlePointsFromXYR(x,y,r) #generate circle points\n",
    "    pl.plot(y_circ, x_circ, 'r-.', lw=4) #plot circle\n",
    "    ax.set_title(title)\n",
    "    fig.colorbar(im)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FitCircle(data):\n",
    "    import numpy as np\n",
    "    from scipy import odr\n",
    "\n",
    "    x,y = np.where(data>=0)\n",
    "#     x = np.r_[  9, 35, -13,  10,  23,   0]\n",
    "#     y = np.r_[ 34, 10,   6, -14,  27, -10]\n",
    "    \n",
    "    x_m = np.mean(x)\n",
    "    y_m = np.mean(y)\n",
    "    \n",
    "    method_3  = \"odr\"\n",
    "\n",
    "    import functools\n",
    "    def countcalls(fn):\n",
    "        \"decorator function count function calls \"\n",
    "\n",
    "        @functools.wraps(fn)\n",
    "        def wrapped(*args):\n",
    "            wrapped.ncalls +=1\n",
    "            return fn(*args)\n",
    "\n",
    "        wrapped.ncalls = 0\n",
    "        return wrapped\n",
    "    \n",
    "    @countcalls\n",
    "    def calc_R(xc, yc):\n",
    "        \"\"\" calculate the distance of each 2D points from the center (xc, yc) \"\"\"\n",
    "        return np.sqrt((x-xc)**2 + (y-yc)**2)\n",
    "\n",
    "    @countcalls\n",
    "    def f_3(beta, x):\n",
    "        \"\"\" implicit definition of the circle \"\"\"\n",
    "        return (x[0]-beta[0])**2 + (x[1]-beta[1])**2 -beta[2]**2\n",
    "\n",
    "    # initial guess for parameters\n",
    "    R_m = calc_R(x_m, y_m).mean()\n",
    "    beta0 = [ x_m, y_m, R_m]\n",
    "\n",
    "    # for implicit function :\n",
    "    #       data.x contains both coordinates of the points\n",
    "    #       data.y is the dimensionality of the response\n",
    "    lsc_data   = odr.Data(np.row_stack([x, y]), y=1)\n",
    "    lsc_model  = odr.Model(f_3, implicit=True)\n",
    "    lsc_odr    = odr.ODR(lsc_data, lsc_model, beta0)\n",
    "    lsc_out    = lsc_odr.run()\n",
    "\n",
    "    xc_3, yc_3, R_3 = lsc_out.beta\n",
    "    Ri_3       = calc_R(xc_3, yc_3)\n",
    "    residu_3   = sum((Ri_3 - R_3)**2)\n",
    "    residu2_3  = sum((Ri_3**2-R_3**2)**2)\n",
    "    ncalls_3   = f_3.ncalls\n",
    "\n",
    "    # == METHOD 3b ==\n",
    "    # Advanced usage, with jacobian\n",
    "    method_3b  = \"odr with jacobian\"\n",
    "    print \"\\nMethod 3b : \", method_3b\n",
    "\n",
    "    @countcalls\n",
    "    def f_3b(beta, x):\n",
    "        \"\"\" implicit definition of the circle \"\"\"\n",
    "        return (x[0]-beta[0])**2 + (x[1]-beta[1])**2 -beta[2]**2\n",
    "\n",
    "    @countcalls\n",
    "    def jacb(beta, x):\n",
    "        \"\"\" Jacobian function with respect to the parameters beta.\n",
    "        return df_3b/dbeta\n",
    "        \"\"\"\n",
    "        xc, yc, r = beta\n",
    "        xi, yi    = x\n",
    "\n",
    "        df_db    = np.empty((beta.size, x.shape[1]))\n",
    "        df_db[0] =  2*(xc-xi)                     # d_f/dxc\n",
    "        df_db[1] =  2*(yc-yi)                     # d_f/dyc\n",
    "        df_db[2] = -2*r                           # d_f/dr\n",
    "\n",
    "        return df_db\n",
    "\n",
    "    @countcalls\n",
    "    def jacd(beta, x):\n",
    "        \"\"\" Jacobian function with respect to the input x.\n",
    "        return df_3b/dx\n",
    "        \"\"\"\n",
    "        xc, yc, r = beta\n",
    "        xi, yi    = x\n",
    "\n",
    "        df_dx    = np.empty_like(x)\n",
    "        df_dx[0] =  2*(xi-xc)                     # d_f/dxi\n",
    "        df_dx[1] =  2*(yi-yc)                     # d_f/dyi\n",
    "\n",
    "        return df_dx\n",
    "\n",
    "\n",
    "    def calc_estimate(data):\n",
    "        \"\"\" Return a first estimation on the parameter from the data  \"\"\"\n",
    "        xc0, yc0 = data.x.mean(axis=1)\n",
    "        r0 = np.sqrt((data.x[0]-xc0)**2 +(data.x[1] -yc0)**2).mean()\n",
    "        return xc0, yc0, r0\n",
    "\n",
    "    # for implicit function :\n",
    "    #       data.x contains both coordinates of the points\n",
    "    #       data.y is the dimensionality of the response\n",
    "    lsc_data  = odr.Data(np.row_stack([x, y]), y=1)\n",
    "    lsc_model = odr.Model(f_3b, implicit=True, estimate=calc_estimate, fjacd=jacd, fjacb=jacb)\n",
    "    lsc_odr   = odr.ODR(lsc_data, lsc_model)    # beta0 has been replaced by an estimate function\n",
    "    lsc_odr.set_job(deriv=3)                    # use user derivatives function without checking\n",
    "    lsc_odr.set_iprint(iter=1, iter_step=1)     # print details for each iteration\n",
    "    lsc_out   = lsc_odr.run()\n",
    "\n",
    "    xc_3, yc_3, R_3 = lsc_out.beta\n",
    "    Ri_3       = calc_R(xc_3, yc_3)\n",
    "    residu_3   = sum((Ri_3 - R_3)**2)\n",
    "    residu2_3  = sum((Ri_3**2-R_3**2)**2)\n",
    "    ncalls_3   = f_3.ncalls\n",
    "\n",
    "    print \"\\nFunctions calls : f_3b=%d jacb=%d jacd=%d\" % (f_3b.ncalls, jacb.ncalls, jacd.ncalls)\n",
    "\n",
    "    \n",
    "#     def PlotAll():\n",
    "#         f = pl.figure( facecolor='white')  #figsize=(7, 5.4), dpi=72,\n",
    "#         pl.axis('equal')\n",
    "\n",
    "#         theta_fit = np.linspace(-np.pi, np.pi, 180)\n",
    "\n",
    "#         x_fit3 = xc_3 + R_3*np.cos(theta_fit)\n",
    "#         y_fit3 = yc_3 + R_3*np.sin(theta_fit)\n",
    "#         pl.plot(x_fit3, y_fit3, 'r-.', label=method_3, lw=2)\n",
    "\n",
    "#         pl.plot(xc_3, yc_3, 'x', ms=10)\n",
    "        \n",
    "#         pl.plot(x, y, 'o', label='data', ms=3)#, mec='b', mew=1)\n",
    "#         pl.show()\n",
    "    \n",
    "#     PlotAll()\n",
    "\n",
    "    return xc_3, yc_3, R_3\n",
    "\n",
    "        \n",
    "FitCircle(deriv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Snippet for examples of annotating images (not mine):\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('bold figure suptitle', fontsize=14, fontweight='bold')\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "fig.subplots_adjust(top=0.85)\n",
    "ax.set_title('axes title')\n",
    "\n",
    "ax.set_xlabel('xlabel')\n",
    "ax.set_ylabel('ylabel')\n",
    "\n",
    "ax.text(3, 8, 'boxed italics text in data coords', style='italic',\n",
    "        bbox={'facecolor':'red', 'alpha':0.5, 'pad':10})\n",
    "\n",
    "ax.text(2, 6, r'an equation: $E=mc^2$', fontsize=15)\n",
    "\n",
    "# ax.text(3, 2, u'unicode: Institut f\\374r Festk\\366rperphysik')\n",
    "\n",
    "ax.text(0.95, 0.01, 'colored text in axes coords',\n",
    "        verticalalignment='bottom', horizontalalignment='right',\n",
    "        transform=ax.transAxes,\n",
    "        color='green', fontsize=15)\n",
    "\n",
    "\n",
    "ax.plot([2], [1], 'o')\n",
    "ax.annotate('annotate', xy=(2, 1), xytext=(3, 4),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "\n",
    "ax.axis([0, 10, 0, 10])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Snippet to text out luminance balancing of colour maps:\n",
    "image = np.zeros((256,256), dtype = np.float)\n",
    "a = fn.makeGaussian(256,1500,50,[100,100])\n",
    "image += a\n",
    "print np.max(a)\n",
    "fn.DisplayImage(image, cmap='jet')\n",
    "fn.DisplayImage(image, cmap='gray')\n",
    "fn.DisplayImage(image, cmap='winter')\n",
    "fn.DisplayImage(image, cmap='cubehelix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#     PEAK_SETTINGS_CENTROIDED = {}\n",
    "#     PEAK_SETTINGS_CENTROIDED['vector'] = global_TOF_centroided\n",
    "#     PEAK_SETTINGS_CENTROIDED['widths'] = np.asarray([3])\n",
    "#     PEAK_SETTINGS_CENTROIDED['min_snr']    = [0.015]\n",
    "#     PEAK_SETTINGS_CENTROIDED['noise_perc'] = [0.0001]\n",
    "\n",
    "#     peaks_centroided = findpeaks( **PEAK_SETTINGS_CENTROIDED)\n",
    "\n",
    "#     if fig is None:\n",
    "#         print 'declared new fig'\n",
    "#         fig = pl.figure(figsize=[16,8])\n",
    "#     ax_cent = pl.subplot(212)\n",
    "#     ax_raw  = pl.subplot(211, sharex=ax_cent)\n",
    "#     tof1 = ax_cent.plot(range(11810),global_TOF_centroided)\n",
    "#     tof2 =  ax_raw.plot(range(11810),global_TOF)\n",
    "#     ax_cent.set_ylim([0,max(global_TOF_centroided[TOF_TMIN:TOF_TMAX])])\n",
    "#     ax_raw.set_ylim([0,max(global_TOF[TOF_TMIN:TOF_TMAX])])\n",
    "#     ax_cent.set_xlim([TOF_TMIN,TOF_TMAX])\n",
    "#     ax_raw.set_xlim([TOF_TMIN,TOF_TMAX])\n",
    "#     if flip:\n",
    "#         ax_cent.set_xlim(ax_cent.get_xlim()[::-1])\n",
    "#     ax_cent.set_title('ToF Centroided')\n",
    "\n",
    "#     FilterPeaks()\n",
    "#     print 'Centroided peaks found at %s'%peaks_centroided[::-1]\n",
    "#     print '       Raw peaks found at %s'%peaks_raw[::-1]\n",
    "\n",
    "#     if ax_cent is not None:\n",
    "#         for peak in peaks_centroided:\n",
    "#             ax_cent.plot([peak, peak], [0, ax_cent.get_ylim()[1]], color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "#     for peak in peaks_raw:\n",
    "#         ax_raw.plot([peak, peak], [0, ax_raw.get_ylim()[1]], color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "#     ax_raw.set_title('ToF RAW')\n",
    "\n",
    "# #     f.savefig(out_path + 'ToF.png')\n",
    "#     pl.show()\n",
    "\n",
    "#     return ax_raw, ax_cent\n",
    "\n",
    "\n",
    "# def FilterPeaks():\n",
    "#     import operator\n",
    "#     search_range = 5\n",
    "#     cent_threshold = len(tp_data) / 10\n",
    "#     raw_threshold = len(loaded_fileNAMES) * 2\n",
    "#     global peaks_centroided\n",
    "#     global peaks_raw\n",
    "#     new_peaks_centroided = []\n",
    "#     new_peaks_raw = []\n",
    "\n",
    "#     for peak in peaks_centroided:\n",
    "#         _min = max(peak - search_range, 0)\n",
    "#         _max = min(peak + search_range, len(global_TOF_centroided))\n",
    "#         index, maxval = max(enumerate(global_TOF_centroided[_min:_max]), key=operator.itemgetter(1))\n",
    "#         if maxval >= cent_threshold:\n",
    "#             new_peaks_centroided.append(_min+index)\n",
    "\n",
    "#     for peak in peaks_raw:\n",
    "#         _min = max(peak - search_range, 0)\n",
    "#         _max = min(peak + search_range, len(global_TOF))\n",
    "#         index, maxval = max(enumerate(global_TOF[_min:_max]), key=operator.itemgetter(1))\n",
    "#         if maxval >= raw_threshold:\n",
    "#             new_peaks_raw.append(_min+index)\n",
    "\n",
    "#     peaks_centroided = new_peaks_centroided\n",
    "#     peaks_raw = new_peaks_raw"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
